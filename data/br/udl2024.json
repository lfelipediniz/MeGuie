{
  "googleCalendar": "https://calendar.google.com/calendar/u/0?cid=Y2YwMTZkNWIwYzkzZmU5MDBhMTc4NDE1MzY1ZjI0NDM5MjQzMGM1ZWQ1MGJkNGRiYTE1NjY1ZjBlZmFkZjgzOEBncm91cC5jYWxlbmRhci5nb29nbGUuY29t",
  "days": [
    {
      "date": "2024-10-14",
      "lectures": [
        {
          "title": "Multilingual LLMs",
          "start_time": "13:00",
          "description": "Sebastian Ruder é um cientista pesquisador baseado em Berlim, Alemanha. Ele lidera a equipe de Multilinguismo na Cohere, cuja missão é melhorar as capacidades multilíngues dos grandes modelos de linguagem (LLMs) da Cohere. Antes disso, ele foi um cientista pesquisador no Google DeepMind. Ele concluiu seu PhD em Processamento de Linguagem Natural (NLP) no Insight Research Centre for Data Analytics, enquanto trabalhava como cientista pesquisador na startup de análise de texto AYLIEN, sediada em Dublin. Anteriormente, ele estudou Linguística Computacional na Universidade de Heidelberg, Alemanha, e no Trinity College, Dublin.",
          "speaker": {
            "name": "Sebastian Ruder",
            "photo": "/images/udl2024/sebastian_ruder.png",
            "description": "Sebastian Ruder é um cientista pesquisador da Cohere, especialista em LLMs multilinguais, com passagem pela Google DeepMind."
          },
          "eventReminder": "https://www.youtube.com/live/5u4r33DLg-U?si=7_voIzQQUUnIWgVo"
        },
        {
          "title": "Metrized Deep Learning",
          "start_time": "14:30",
          "description": "Jeremy Bernstein é bacharel em Física Experimental e Teórica pelo Trinity College, e Ph.D. em Computação e Sistemas Neurais pelo Caltech atualmente é pesquisador de pós-doutorado no Massachusetts Institute of Technology (MIT). Sua pesquisa se concentra nas bases matemáticas da inteligência natural e artificial. Entre seus principais interesses estão a descoberta das leis computacionais e estatísticas que regem a inteligência, tanto natural quanto artificial, com o objetivo de projetar sistemas de aprendizado mais eficientes, automáticos e úteis na prática, além de explorar as implicações sociais da inteligência artificial.",
          "speaker": {
            "name": "Jeremy Bernstein",
            "photo": "/images/udl2024/jeremy_bernstein.png",
            "description": "Jeremy Bernstein é pesquisador de pós-doutorado no MIT, especializado em inteligência natural e artificial."
          },
          "eventReminder": "https://www.youtube.com/live/BmxAdQ1mvRQ?si=RPxTydjtVLL2gr1V"
        }
      ]
    },
    {
      "date": "2024-10-15",
      "lectures": [
        {
          "title": "Fundamentos da transferibilidade entre domínios em redes neurais",
          "start_time": "13:00",
          "description": "Bruno Ribeiro é professor associado no Departamento de Ciência da Computação da Purdue University e professor associado visitante na Stanford University entre 2023-2024. Antes de ingressar na Purdue, ele obteve um BSc e MEng pela UFRJ, um Ph.D. pela University of Massachusetts Amherst e foi um pós-doutorado na Carnegie Mellon University. Ribeiro fez contribuições significativas na interseção entre aprendizado profundo geométrico, redes neurais de grafos, robustez fora da distribuição e aprendizado de máquina. Ribeiro recebeu um prêmio NSF CAREER em 2020 sobre os fundamentos do aprendizado de máquina de grafos, um Amazon Research Award em 2022 e vários prêmios de melhor artigo.",
          "speaker": {
            "name": "Bruno Ribeiro",
            "photo": "/images/udl2024/bruno_ribeiro.png",
            "description": "Bruno Ribeiro é professor associado no Departamento de Ciência da Computação da Purdue University e professor associado visitante na Stanford University entre 2023-2024. Antes de ingressar na Purdue, ele obteve um BSc e MEng pela UFRJ, um Ph.D. pela University of Massachusetts Amherst e foi um pós-doutorado na Carnegie Mellon University. Ribeiro fez contribuições significativas na interseção entre aprendizado profundo geométrico, redes neurais de grafos, robustez fora da distribuição e aprendizado de máquina. Ribeiro recebeu um prêmio NSF CAREER em 2020 sobre os fundamentos do aprendizado de máquina de grafos, um Amazon Research Award em 2022 e vários prêmios de melhor artigo."
          },
          "eventReminder": "https://www.youtube.com/live/wh0GSMyphBI?si=FOLTafu35C7NwpDz"
        },
        {
          "title": "Representação de Imagens em Multirresolução usando Redes Neurais",
          "start_time": "14:30",
          "description": "Hallison Paz é pesquisador em AI Graphics, interseção entre inteligência artificial e computação gráfica, e co-criador do canal Programação Dinâmica e do projeto Matemática Elementar para Computação. É graduado em engenharia de computação pelo Instituto Militar de Engenharia, além de mestre e doutorando no laboratório de visão computacional e computação gráfica (Visgraf) do Instituto Nacional de Matemática Pura e Aplicada, onde pesquisa aplicações de machine learning para novas mídias. Tem experiência na análise, projeto e desenvolvimento de soluções e modelos de inteligência artificial, e passagem como pesquisador no Reality Labs Research, divisão de realidade virtual e aumentada da Meta.",
          "speaker": {
            "name": "Hallison Paz",
            "photo": "/images/udl2024/hallison_paz.png",
            "description": "Hallison Paz é pesquisador em AI Graphics, co-criador do canal Programação Dinâmica e especialista em computação gráfica."
          },
          "eventReminder": "https://www.youtube.com/live/WmaWecH0ThU?si=isrZWW-NUyZBRIlQ"
        },
        {
          "title": "Generative Models for Biomolecular Prediction, Dynamics, and Design",
          "start_time": "16:00",
          "description": "Hannes Stärk é um aluno do terceiro ano de doutorado no MIT trabalhando com Regina Barzilay e Tommi Jaakkola em modelos generativos para biomoléculas.",
          "speaker": {
            "name": "Hannes Stärk",
            "photo": "/images/udl2024/hannes_stark.png",
            "description": "Apresentamos três caminhos nos quais achamos que modelos generativos são especialmente valiosos para modelar biomoléculas. 1) Tarefas de predição difíceis podem ser melhor abordadas com modelos generativos que podem sugerir e classificar múltiplas soluções (por exemplo, encaixe). 2) A dinâmica e conformações de biomoléculas podem ser capturadas com modelos generativos (por exemplo, conjuntos conformacionais de proteínas e trajetórias de MD). 3) O design de novas biomoléculas pode ser acelerado, informado por amostras ou probabilidades de modelos generativos (por exemplo, ligante de proteína ou design de DNA regulatório)."
          },
          "eventReminder": "https://www.youtube.com/live/eykxZeUDlKo?si=oKaaHZhfCT_74Y7x"
        }
      ]
    },
    {
      "date": "2024-10-16",
      "lectures": [
        {
          "title": "Modelos de Linguagem Multilíngue: benefícios e barreiras",
          "start_time": "13:00",
          "description": "Processamento de Linguagem Natural Multilingual tem desempenhado um papel fundamental nos recentes avanços dos LLM 's. A habilidade de entender e gerar textos em múltiplas línguas expandiu as capacidades desses modelos, tornando eles mais versáteis e acessíveis para uma audiência global. Nessa palestra, nós exploramos o atual estado de LLM 's multilingual, abordando desafios e oportunidades que virão pela frente. A discussão irá cobrir tópicos críticos como a escassez de bases de dados multilíngues, avaliação e benchmarking de modelos multilíngues, e das considerações de segurança ao lidar com diversas línguas. Adicionalmente, a palestra vai destacar os desafios e ganhos de esforços globais open science, como o Aya, para construir estado-da-arte modelos e bases de dados multilíngues. Finalmente, nós discutimos as áreas inexploradas em PLN multilíngue, providenciando insights para direções para pesquisas futuras e os esforços contínuos para melhorar a performance e aplicabilidade dos LLMs.",
          "speaker": {
            "name": "Marzieh Fadaee",
            "photo": "/images/udl2024/marzieh_fadaee.png",
            "description": "Marzieh Fadaee é uma cientista pesquisadora sênior na Cohere for AI, um laboratório de pesquisa sem fins lucrativos da Cohere, onde ela foca em investigação fundamental e resolução de desafios complexos em Processamento de Linguagem Natural (PLN) e construir e melhorar modelos de linguagem. Ela co-lidera a iniciativa Aya, a qual levou à criação do maior dataset de instrução multilingual e do desenvolvimento de uma série de estado-da-arte modelos de linguagem multilingual. Antes de se juntar à Cohere for AI, Marzieh foi a pesquisadora líder de NLP/ML na Zeta Alpha Vector, onde ela foi a pioneira em abordagens inovativas para a descoberta e organização do conhecimento. Ela tem um doutorado pela Universidade de Amsterdã onde estudou modelos de redes neurais para tradução."
          },
          "eventReminder": "https://www.youtube.com/live/i8hQeFD-P1I?si=u1mU4bl4wywPRis2"
        },
        {
          "title": "Geometric Deep Learning",
          "start_time": "14:30",
          "description": "Petar Veličković é pesquisador sênior no Google DeepMind, professor afiliado na Universidade de Cambridge e associado do Clare Hall, Cambridge. Ele possui um doutorado em Ciência da Computação pela Universidade de Cambridge (Trinity College). Sua pesquisa se concentra em geometric deep learning—desenvolvendo arquiteturas de redes neurais que respeitam as invariâncias e simetrias nos dados (um tema sobre o qual ele co-escreveu um proto-livro). Por suas contribuições, ele é reconhecido como um ELLIS Scholar no Programa de Geometric Deep Learning. Seu foco principal é em aprendizado de representação para grafos e suas aplicações no raciocínio algorítmico (destacado no VentureBeat). Ele é o primeiro autor dos Graph Attention Networks—uma camada de convolução popular para grafos—e do Deep Graph Infomax—um pipeline de aprendizado auto-supervisionado popular para grafos (destacado no ZDNet). Sua pesquisa foi utilizada para melhorar significativamente as previsões de tempo de viagem no Google Maps (destacada na CNBC, Endgadget, VentureBeat, CNET, The Verge e ZDNet), além de orientar a intuição de matemáticos na formulação de novos teoremas e conjecturas de alto nível.",
          "speaker": {
            "name": "Petar Veličković",
            "photo": "/images/udl2024/petar_velickovic.png",
            "description": "Petar Veličković é pesquisador sênior no Google DeepMind, especialista em aprendizado geométrico e grafos."
          },
          "eventReminder": "https://www.youtube.com/live/IZS0IUxdWfs?si=VMHfeMEa_iBNubJ"
        },
        {
          "title": "Uma introdução ao aprendizado por reforço",
          "start_time": "16:00",
          "description": "Victor Ulisses Pugliese é um doutorando em Ciência da Computação pela UNIFESP, com foco em Aprendizado por Reforço e Problemas de Otimização. Ele também possui mestrado pelo ITA em engenharia da computação, focado em Aprendizado de Máquina, Problemas Supervisionados e Concept Drift. Possui MBA em Engenharia de Software com métodos ágeis, pelo IGTI. É graduado em análise de sistemas pelo IFSP. Pugliesi tem mais de dez publicações acadêmicas em Aprendizado de Máquina e Engenharia de Software. Tem experiência profissional como desenvolvedor em diversas linguagens de programação. Ele tem 4 anos de experiência no campo de ciência de dados na companhia Compsis utilizando python, Neo4J, Kafka, Airflow e outras tecnologias. Adicionalmente, ele fundou o GDG de Caraguatatuba, para providenciar conversas técnicas e tecnológicas entre sua comunidade.",
          "speaker": {
            "name": "Victor Pugliese",
            "photo": "/images/udl2024/victor_pugliese.png",
            "description": "Victor Pugliese é doutorando na UNIFESP, especializado em aprendizado por reforço e otimização."
          },
          "eventReminder": "https://www.youtube.com/live/YFlLPW4_Qc0?si=yDqeLz8GjBchG9Vw"
        }
      ]
    },
    {
      "date": "2024-10-17",
      "lectures": [
        {
          "title": "Revisitando os fundamentos da aprendizagem por reforço profundo para aprender continuamente",
          "start_time": "13:00",
          "description": "A capacidade de aprender continuamente é essencial em um mundo complexo e em mudança. Isto também é verdade para agentes artificiais orientados por objetivos que interagem com o mundo. Para terem sucesso, os agentes de aprendizagem contínua, à semelhança dos agentes mais tradicionais, precisam de enfrentar os desafios de exploração, generalização e atribuição de créditos inerentes aos problemas de tomada de decisão sequencial. No entanto, o aspecto interminável do problema coloca novos desafios, de tal forma que soluções bem estabelecidas, como as provenientes da literatura tradicional de aprendizagem por reforço profundo, não são tão eficazes. Nesta palestra, revisitarei alguns dos princípios básicos da aprendizagem por reforço profundo e discutirei como as técnicas tradicionais têm dificuldade em enfrentar os desafios fundamentais da tomada de decisões sequenciais no ambiente de aprendizagem contínua. Também apresentarei alguns de nossos resultados recentes mostrando a eficácia das abstrações temporais no combate à exploração, os benefícios de aproveitar representações discretas para uma melhor generalização e como lidar com o fenômeno bem documentado das redes neurais que perdem sua capacidade de aprender ao longo do tempo.",
          "speaker": {
            "name": "Marlos C. Machado",
            "photo": "/images/udl2024/marlos_machado.png",
            "description": "Marlos C. Machado é professor assistente na Universidade de Alberta. Seus interesses de pesquisa residem amplamente em aprendizado de máquina, especificamente em aprendizado de reforço (profundo), aprendizado de representação, aprendizado contínuo e aplicações no mundo real de todos os itens acima. Ele também é bolsista do Alberta Machine Intelligence Institute (Amii), diretor do Canada CIFAR AI através da Amii e investigador principal do grupo Reinforcement Learning and Artificial Intelligence (RLAI). Ele completou seu bacharelado e mestrado na UFMG, Brasil, e seu doutorado na Universidade de Alberta. Durante seu doutorado, entre outras coisas, ele introduziu estocasticidade e modos de jogo no popular Arcade Learning Environment, e popularizou a ideia de exploração temporalmente estendida por meio de opções, introduzindo a ideia de opções próprias. Antes de se tornar professor, foi pesquisador da DeepMind e do Google Brain por quatro anos; durante esse período ele fez diversas contribuições para o aprendizado por reforço, incluindo a aplicação do aprendizado por reforço profundo para controlar os balões estratosféricos de Loon, publicado na Nature. Sua pesquisa foi apresentada em mídias populares como BBC, Bloomberg TV, The Verge e Wired."
          },
          "eventReminder": "https://www.youtube.com/live/DNkSa8A3bAs?si=sR1N7Kee2N3E1ESp"
        },
        {
          "title": "IA e Tomada de Decisão Autônoma: O Dilema Ético",
          "start_time": "14:30",
          "description": "Os sistemas autônomos que tomam decisões por conta própria, como veículos autônomos, sistemas de recomendação de sentenças judiciais, assistentes de saúde ou mesmo IA em processos de contratação, apresentam dilemas éticos complexos. O avanço dessas tecnologias exige uma reflexão profunda sobre quem é responsável pelos erros ou consequências inesperadas que surgem dessas decisões. Esses sistemas estão cada vez mais assumindo papéis críticos que impactam diretamente a vida das pessoas, e as questões sobre responsabilidade, confiabilidade e transparência são fundamentais. Responsabilidade na Pesquisa e Desenvolvimento: Pesquisadores e desenvolvedores de IA têm a responsabilidade de considerar essas questões desde as primeiras fases de desenvolvimento de algoritmos. Essas considerações levantam a pergunta crítica: até que ponto devemos permitir que sistemas autônomos tomem decisões de grande impacto sem intervenção humana, e como podemos garantir que essas decisões sejam sempre justas, transparentes e responsáveis?",
          "speaker": {
            "name": "Nina Da Hora",
            "photo": "/images/udl2024/ninadahora.png",
            "description": "Minha pesquisa visa mitigar o racismo algorítmico através da interseção entre justiça e inteligência artificial no meu mestrado na Unicamp. Fui premiada com o Ford Foundation Global Fellowship 2024, o prêmio Forbes Under 30, o Sabia Award da Universidade de Cambridge e estou listada entre as 100 pessoas mais influentes em Ética em IA. Em 2020, fundei o Instituto da Hora, dedicado ao avanço dos direitos digitais no Brasil e à promoção de uma abordagem mais coletiva e crítica do campo da inteligência artificial na sociedade. Sou pesquisador sênior em Data Scientist na Thoughtworks Brasil e colaboro ativamente em conselhos da sociedade civil, indústria e governo, liderando e influenciando políticas e inovações responsáveis em IA."
          },
          "eventReminder": "https://www.youtube.com/live/xh1lZYqNwfk?si=IPr18hmZMSwCaFQk"
        },
        {
          "title": "Inteligência Artificial no Combate ao Abuso Sexual Infantil",
          "start_time": "16:00",
          "description": "O projeto Araceli é uma parceria UNICAMP-UFMG-USP que desenvolve soluções de Inteligência Artificial para a detecção automática de materiais de abuso sexual infantil (child sexual abuse material, CSAM). Contamos com colaborações essenciais com a Polícia Federal e Polícia Técnico-Científica do Estado de São Paulo, pois apenas profissionais treinados podem manipular este tipo de dado. Neste Seminário vamos falar sobre o processo de trabalhar com estes materiais, como obter resultados sem ter acesso direto ao conteúdo sensível e trabalhos específicos realizados com protocolos de Auto-supervisão e Aprendizado Few-shot.",
          "speaker": {
            "name": "Leo Sampaio Ferraz Ribeiro",
            "photo": "/images/udl2024/leo_sampaio.png",
            "description": "Professora doutora no ICMC-USP. Obteve o título de Doutora em Ciências de Computação pelo ICMC-USP e foi pesquisadora em pós-doutorado na Universidade Estadual de Campinas (Unicamp). Atua como pesquisadora da área de Visão Computacional, com experiência específica no desenvolvimento de modelos multimodais voltados para busca entre domínios. Além do problema de busca multimodal a pesquisadora atua também no reconhecimento de conteúdos sensíveis sob protocolos de poucos dados e generalização de domínios."
          },
          "eventReminder": "https://www.youtube.com/live/fh0yOKnt6is?si=eGOqaEGS5ZRtXgQY"
        }
      ]
    },
    {
      "date": "2024-10-18",
      "lectures": [
        {
          "title": "Pesquisa empírica em aprendizagem por reforço",
          "start_time": "13:00",
          "description": "João é um pesquisador brasileiro que trabalha no Google DeepMind em Londres. João trabalhou em LLMs, Aprendizado por Reforço e Teoria de Categoria para Aprendizado Profundo, e é apaixonado por tentar entender como e por que o Aprendizado Profundo funciona. Ele também adora matemática e gosta de jogar jogos de tabuleiro e pintar miniaturas.",
          "speaker": {
            "name": "João Guilherme Madeira Araújo",
            "photo": "/images/udl2024/joao_araújo.png",
            "description": "Estudante de Ciencias da Computação no ICMC, medalhista em mais de 30 olimpíadas dos conhecimento e co-fundador do CodCad."
          },
          "eventReminder": "https://www.youtube.com/live/t3KBLHGghRg?si=JYTQA5MrYp7v6Fof"
        },
        {
          "title": "Uma visão geral amigável dos transformadores e do mecanismo de atenção",
          "start_time": "14:30",
          "description": "Nesta palestra, aprenderemos a arquitetura de um transformador, incluindo suas partes importantes, como a rede neural feedforward, tokenização e codificação posicional. Uma ênfase especial será feita em embeddings e no mecanismo de atenção, e como eles capturam o contexto do texto. Esta palestra é aberta a todos os públicos.",
          "speaker": {
            "name": "Luis Serrano",
            "photo": "/images/udl2024/luis_Serrano.png",
            "description": "Luis Serrano é o autor de Grokking Machine Learning e o criador do popular canal educacional do YouTube Serrano.Academy. Luis trabalhou em grandes modelos de linguagem na Cohere, em inteligência artificial no Google e na Apple e como cientista de pesquisa de IA quântica na Zapata Computing. Ele tem cursos populares de ML em plataformas como Udacity e Coursera. Luis tem um PhD em matemática pela University of Michigan e um mestrado e bacharelado pela University of Waterloo."
          },
          "eventReminder": "https://www.youtube.com/live/NDG-4Q2fLP8?si=yr6On1QVIV0W8AQu"
        },
        {
          "title": "Deep Learning aplicado ao diagnóstico de transtornos de saúde mental (depressão) utilizando material genético humano (DNA) e fatores ambientais.",
          "start_time": "16:00",
          "description": "Rafael é um pesquisador de pós-doutorado na Universidade de Purdue, tem doutorado em física aplicada pela UNICAMP, onde utilizou aprendizado profundo e técnicas de PLN para detectar fake news no Twitter durante a pandemia do COVID-19.",
          "speaker": {
            "name": "Rafael Geurgas Zavarizz",
            "photo": "/images/udl2024/rafael_zavarizz.png",
            "description": "Rafael Zavarizz é pós-doutor na Purdue University, especializado em aprendizado profundo e PLN para detecção de fake news."
          },
          "eventReminder": "https://www.youtube.com/live/rTJi4HHcTV8?si=QkPkI8mMRwWxTHJ2"
        }
      ]
    }
  ]
}

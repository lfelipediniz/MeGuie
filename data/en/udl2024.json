{
  "googleCalendar": "https://calendar.google.com/calendar/u/0?cid=Y2YwMTZkNWIwYzkzZmU5MDBhMTc4NDE1MzY1ZjI0NDM5MjQzMGM1ZWQ1MGJkNGRiYTE1NjY1ZjBlZmFkZjgzOEBncm91cC5jYWxlbmRhci5nb29nbGUuY29t",
  "days": [
    {
      "date": "2024-10-14",
      "lectures": [
        {
          "title": "Multilingual LLMs",
          "start_time": "13:00",
          "description": "Sebastian Ruder is a research scientist based in Berlin, Germany. He leads the Multilinguality team at Cohere whose mission is to improve the multilingual capabilities of Cohere's large language models (LLMs). Before that he was a research scientist at Google DeepMind. He completed his PhD in Natural Language Processing (NLP) at the Insight Research Centre for Data Analytics, while working as a research scientist at Dublin-based text analytics startup AYLIEN. Previously, he studied Computational Linguistics at the University of Heidelberg, Germany and at Trinity College, Dublin.",
          "speaker": {
            "name": "Sebastian Ruder",
            "photo": "/images/udl2024/sebastian_ruder.png",
            "description": "Sebastian Ruder is a research scientist based in Berlin, Germany. He leads the Multilinguality team at Cohere whose mission is to improve the multilingual capabilities of Cohere's large language models (LLMs). Before that he was a research scientist at Google DeepMind. He completed his PhD in Natural Language Processing (NLP) at the Insight Research Centre for Data Analytics, while working as a research scientist at Dublin-based text analytics startup AYLIEN. Previously, he studied Computational Linguistics at the University of Heidelberg, Germany and at Trinity College, Dublin."
          },
          "eventReminder": "https://www.youtube.com/live/5u4r33DLg-U?si=7_voIzQQUUnIWgVo"
        },
        {
          "title": "Metrized Deep Learning",
          "start_time": "14:30",
          "description": "Jeremy Bernstein holds a bachelor's degree in Experimental and Theoretical Physics from Trinity College, and a Ph.D. in Computing and Neural Systems from Caltech and is currently a postdoctoral researcher at the Massachusetts Institute of Technology (MIT). His research focuses on the mathematical foundations of natural and artificial intelligence. His main interests include discovering the computational and statistical laws that govern intelligence, both natural and artificial, with the aim of designing more efficient, automatic and practically useful learning systems, as well as exploring the social implications of artificial intelligence.",
          "speaker": {
            "name": "Jeremy Bernstein",
            "photo": "/images/udl2024/jeremy_bernstein.png",
            "description": "Jeremy Bernstein is a postdoctoral researcher at MIT, specializing in natural and artificial intelligence."
          },
          "eventReminder": "https://www.youtube.com/live/BmxAdQ1mvRQ?si=RPxTydjtVLL2gr1V"
        }
      ]
    },
    {
      "date": "2024-10-15",
      "lectures": [
        {
          "title": "Foundations of Cross-Domain Transferability in Neural Networks",
          "start_time": "13:00",
          "description": "Bruno Ribeiro is an Associate Professor in the Department of Computer Science at Purdue University and a Visiting Associate Professor at Stanford University between 2023-2024. Before joining Purdue, he earned a BSc and MEng from UFRJ, a Ph.D. from the University of Massachusetts Amherst, and was a postdoctoral fellow at Carnegie Mellon University. Ribeiro has made significant contributions in the intersection between geometric deep learning, graph neural networks, out-of-distribution robustness, and machine learning. Ribeiro received an NSF CAREER award in 2020 on the foundations of graph machine learning, an Amazon Research Award in 2022, and multiple best paper awards..",
          "speaker": {
            "name": "Bruno Ribeiro",
            "photo": "/images/udl2024/bruno_ribeiro.png",
            "description": "Bruno Ribeiro is an Associate Professor in the Department of Computer Science at Purdue University and a Visiting Associate Professor at Stanford University between 2023-2024. Before joining Purdue, he earned a BSc and MEng from UFRJ, a Ph.D. from the University of Massachusetts Amherst, and was a postdoctoral fellow at Carnegie Mellon University. Ribeiro has made significant contributions in the intersection between geometric deep learning, graph neural networks, out-of-distribution robustness, and machine learning. Ribeiro received an NSF CAREER award in 2020 on the foundations of graph machine learning, an Amazon Research Award in 2022, and multiple best paper awards."
          },
          "eventReminder": "https://www.youtube.com/live/wh0GSMyphBI?si=FOLTafu35C7NwpDz"
        },
        {
          "title": "Multiresolution Image Representation using Neural Networks",
          "start_time": "14:30",
          "description": " Hallison Paz is a researcher in AI Graphics, the intersection between artificial intelligence and computer graphics, and co-creator of the Dynamic Programming channel and the Elementary Maths for Computing project. He has a degree in computer engineering from the Military Engineering Institute (Brazil), and is a master's and doctoral student at the computer vision and computer graphics laboratory (Visgraf) of the National Institute of Pure and Applied Mathematics, where he researches machine learning applications for new media. He has experience in analysing, designing and developing artificial intelligence solutions and models, and works as a researcher at Reality Labs Research, Meta's virtual and augmented reality division.",
          "speaker": {
            "name": "Hallison Paz",
            "photo": "/images/udl2024/hallison_paz.png",
            "description": "Hallison Paz is a researcher in AI Graphics, co-creator of the Dynamic Programming channel, and an expert in computer graphics."
          },
          "eventReminder": "https://www.youtube.com/live/WmaWecH0ThU?si=isrZWW-NUyZBRIlQ"
        },
        {
          "title": "Generative Models for Biomolecular Prediction, Dynamics, and Design",
          "start_time": "16:00",
          "description": "Hannes Stärk is a Ph.D. student at MIT, working on generative models for biomolecules, exploring how these models can predict and design biomolecules.",
          "speaker": {
            "name": "Hannes Stärk",
            "photo": "/images/udl2024/hannes_stark.png",
            "description": "Hannes Stärk is a Ph.D. student at MIT, working on generative models for biomolecules, exploring how these models can predict and design biomolecules."
          },
          "eventReminder": "https://www.youtube.com/live/eykxZeUDlKo?si=oKaaHZhfCT_74Y7x"
        }
      ]
    },
    {
      "date": "2024-10-16",
      "lectures": [
        {
          "title": "Multilingual Language Models: Benefits and Barriers",
          "start_time": "13:00",
          "description": "Multilingual Natural Language Processing has played a pivotal role in the recent advancements of LLMs. The ability to understand and generate text in multiple languages has expanded the capabilities of these models, making them more versatile and accessible to a global audience. In this talk, we explore the current landscape of multilingual LLMs, addressing the challenges and opportunities that lie ahead. The discussion will cover critical topics such as the scarcity of multilingual datasets, the evaluation and benchmarking of multilingual models, and the unique safety considerations when dealing with diverse languages. Additionally, the talk will highlight the challenges and gains of global open science efforts, such as Aya, to build state-of-the-art multilingual models and datasets. Finally, we discuss the unexplored areas in multilingual NLP, providing insights into potential future research directions and the ongoing efforts to enhance the performance and applicability of LLMs.",
          "speaker": {
            "name": "Marzieh Fadaee",
            "photo": "/images/udl2024/marzieh_fadaee.png",
            "description": "Marzieh Fadaee is a Senior Research Scientist at Cohere for AI, the non-profit research lab of Cohere, where she focuses on fundamental research and solving complex challenges in Natural Language Processing (NLP) and building and improving language models. She co-leads the Aya initiative, which led to the creation of the largest multilingual instruction dataset and the development of a series of state-of-the-art multilingual language models. Before joining Cohere for AI, Marzieh was the NLP/ML Research Lead at Zeta Alpha Vector, where she pioneered innovative approaches to knowledge discovery and organization. She holds a PhD from the University of Amsterdam where she studied neural machine translation models."
          },
          "eventReminder": "https://www.youtube.com/live/i8hQeFD-P1I?si=u1mU4bl4wywPRis2"
        },
        {
          "title": "Geometric Deep Learning",
          "start_time": "14:30",
          "description": "While learning generic functions in high dimensions is a cursed estimation problem, most tasks of interest are not generic, and come with essential pre-defined regularities arising from the underlying low-dimensionality and structure of the physical world. Exploiting the known symmetries of a large system is a powerful and classical remedy against the curse of dimensionality, and forms the basis of most physical theories. Deep learning systems are no exception.",
          "speaker": {
            "name": "Petar Veličković",
            "photo": "/images/udl2024/petar_velickovic.png",
            "description": "Petar Veličković is a Staff Research Scientist at Google DeepMind, Affiliated Lecturer at the University of Cambridge, and an Associate of Clare Hall, Cambridge. He holds a PhD in Computer Science from the University of Cambridge (Trinity College), obtained under the supervision of Pietro Liò. His research concerns geometric deep learning—devising neural network architectures that respect the invariances and symmetries in data (a topic he has co-written a proto-book about). He is recognised as an ELLIS Scholar in the Geometric Deep Learning Program. Particularly, he focuses on graph representation learning and its applications in algorithmic reasoning (featured in VentureBeat). He is the first author of Graph Attention Networks—a popular convolutional layer for graphs—and Deep Graph Infomax—a popular self-supervised learning pipeline for graphs (featured in ZDNet)."
          },
          "eventReminder": "https://www.youtube.com/live/IZS0IUxdWfs?si=VMHfeMEa_iBNubJ"
        },
        {
          "title": "An Introduction to Reinforcement Learning",
          "start_time": "16:00",
          "description": "Victor Ulisses Pugliese. He is a Ph.D. candidate in Computer Science at UNIFESP, focusing on Reinforcement Learning and Optimization Problems. He is also a master at ITA in Computing Engineering, focusing on Machine Learning, Supervised Problems, and Concept Drift. MBA in Software Engineering with Agile Methods, by IGTI. Systems Analyst graduated by IFSP. Pugliese has more than ten academic publications in Machine Learning and Software Engineering. He has professional experience as a developer in several programming languages. He had 4 years in the field of data science by the company Compsis, with python, neo4j, kafka, airflow, and other technologies. In addition, he founded the GDG's Caraguatatuba, to provide technical and technological conversations in his community.",
          "speaker": {
            "name": "Victor Pugliese",
            "photo": "/images/udl2024/victor_pugliese.png",
            "description": "Victor Pugliese is a Ph.D. student at UNIFESP, specializing in reinforcement learning and optimization."
          },
          "eventReminder": "https://www.youtube.com/live/YFlLPW4_Qc0?si=yDqeLz8GjBchG9Vw"
        }
      ]
    },
    {
      "date": "2024-10-17",
      "lectures": [
        {
          "title": "Revisiting the Fundamentals of Deep Reinforcement Learning for Learning Continually",
          "start_time": "13:00",
          "description": "The ability to learn continually is essential in a complex and changing world. This is also true for goal-driven artificial agents that interact with the world. To succeed, continual learning agents, similarly to more traditional agents, need to tackle the challenges of exploration, generalization, and credit assignment inherent to sequential decision-making problems. However, the never-ending aspect of the problem poses new challenges such that well-established solutions, such as those coming from the traditional deep reinforcement learning literature, are not so effective. In this talk, I will revisit some of the basics of deep reinforcement learning, and I will discuss how traditional techniques struggle with the fundamental challenges of sequential decision-making in the continual learning setting. I will also present some of our recent results showing the effectiveness of temporal abstractions in tackling exploration, the benefits of harnessing discrete representations for better generalization, and how to deal with the well-documented phenomenon of neural networks losing their ability to learn over time.",
          "speaker": {
            "name": "Marlos C. Machado",
            "photo": "/images/udl2024/marlos_machado.png",
            "description": "Marlos C. Machado is an assistant professor at the University of Alberta. His research interests lie broadly in machine learning, specifically in (deep) reinforcement learning, representation learning, continual learning, and real-world applications of all the above. He is also an Alberta Machine Intelligence Institute (Amii) Fellow, a Canada CIFAR AI Chair through Amii, and a principal investigator in the Reinforcement Learning and Artificial Intelligence (RLAI) group. He completed his B.Sc. and M.Sc. at UFMG, Brazil, and his Ph.D. at the University of Alberta. During his Ph.D., among other things, he introduced stochasticity and game modes in the popular Arcade Learning Environment, and he popularized the idea of temporally-extended exploration through options, introducing the idea of eigenoptions. Before becoming a professor, he was a researcher at DeepMind and at Google Brain for four years; during which time he made several contributions to reinforcement learning, including the application of deep reinforcement learning to control Loon’s stratospheric balloons, published in Nature. His research has been featured in popular media such as BBC, Bloomberg TV, The Verge, and Wired."
          },
          "eventReminder": "https://www.youtube.com/live/DNkSa8A3bAs?si=sR1N7Kee2N3E1ESp"
        },
        {
          "title": "AI and Autonomous Decision Making: The Ethical Dilemma",
          "start_time": "14:30",
          "description": "Autonomous systems that make decisions on their own, such as self-driving cars, judicial sentencing recommendation systems, healthcare assistants, or even AI in hiring processes, present complex ethical dilemmas. The advancement of these technologies requires deep reflection on who is responsible for errors or unintended consequences that arise from these decisions. These systems are increasingly taking on critical roles that directly impact people’s lives, and questions of accountability, trustworthiness, and transparency are paramount. Accountability in R&D: AI researchers and developers have a responsibility to consider these issues from the earliest stages of algorithm development. These considerations raise the critical question: to what extent should we allow autonomous systems to make high-impact decisions without human intervention, and how can we ensure that these decisions are always fair, transparent, and accountable? ",
          "speaker": {
            "name": "Nina Da Hora",
            "photo": "/images/udl2024/ninadahora.png",
            "description": "My research aims at mitigating algorithmic racism through the intersection between justice and artificial intelligence in my master degree ate Unicamp. I have been awarded the Ford Foundation Global Fellowship 2024, the Forbes Under 30 award, the Sabia Award from the University of Cambridge, and am listed among the 100 most influential people in Ethics in AI. In 2020, I founded the Instituto da Hora, dedicated to advancing digital rights in Brazil and promoting a more collective and critical approach to the field of artificial intelligence in society. I am research senior in Data Scientist at Thoughtworks Brazil I actively collaborate on councils of civil society, industry, and government, leading and influencing responsible policies and innovations in AI."
          },
          "eventReminder": "https://www.youtube.com/live/xh1lZYqNwfk?si=IPr18hmZMSwCaFQk"
        },
        {
          "title": "Artificial Intelligence in the Fight against Child Sexual Abuse",
          "start_time": "16:00",
          "description": "The Araceli project is a UNICAMP-UFMG-USP partnership that develops Artificial Intelligence solutions for the automatic detection of child sexual abuse material (CSAM).  In this Seminar we will talk about the process of working with these materials, how to obtain results without having direct access to sensitive content and specific work carried out with Self-supervision and Few-shot Learning protocols.",
          "speaker": {
            "name": "Leo Sampaio Ferraz Ribeiro",
            "photo": "/images/udl2024/leo_sampaio.png",
            "description": "Professor at ICMC-USP. She obtained her PhD in Computer Science from ICMC-USP and was a post-doctoral researcher at the State University of Campinas (Unicamp). She works as a researcher in the field of Computer Vision, with specific experience in the development of multimodal models for cross-domain search. In addition to the multimodal search problem, she also works on the recognition of sensitive content under low-data protocols and domain generalisation."
          },
          "eventReminder": "https://www.youtube.com/live/fh0yOKnt6is?si=eGOqaEGS5ZRtXgQY"
        }
      ]
    },
    {
      "date": "2024-10-18",
      "lectures": [
        {
          "title": "Empirical Research in Reinforcement Learning",
          "start_time": "13:00",
          "description": "João is a Brazilian Research Engineer working at Google DeepMind in London. João has worked on LLMs, Reinforcement Learning, and Category Theory for Deep Learning, and is passionate about trying to fully understand how and why Deep Learning works. He also loves maths and likes playing board games and painting miniatures.",
          "speaker": {
            "name": "João Guilherme Madeira Araújo",
            "photo": "/images/udl2024/joao_araújo.png",
            "description": "Computer Science student at ICMC, medalist in more than 30 knowledge Olympiads and co-founder of CodCad."
          },
          "eventReminder": "https://www.youtube.com/live/t3KBLHGghRg?si=JYTQA5MrYp7v6Fof"
        },
        {
          "title": "A friendly overview of transformers and the attention mechanism",
          "start_time": "14:30",
          "description": "In this talk we'll learn the architecture of a transformer, including its important parts like the feedforward neural network, tokenization, and the positional encoding. A special emphasis will be done in embeddings and the attention mechanism, and how they capture the context of the text. This talk is open to all audiences.",
          "speaker": {
            "name": "Luis Serrano",
            "photo": "/images/udl2024/luis_Serrano.png",
            "description": "Luis Serrano is the author of Grokking Machine Learning, and the creator of the popular educational YouTube channel Serrano.Academy. Luis has worked in large language models at Cohere, in artificial intelligence at Google and Apple, and as a quantum AI research scientist at Zapata Computing. He has popular ML courses in platforms such as Udacity and Coursera. Luis has a PhD in mathematics from the University of Michigan, and a masters and bachelors from the University of Waterloo."
          },
          "eventReminder": "https://www.youtube.com/live/NDG-4Q2fLP8?si=yr6On1QVIV0W8AQu"
        },
        {
          "title": "Deep Learning applied to the diagnosis of mental health disorders (depression) using human genetic material (DNA) and environmental factors.",
          "start_time": "16:00",
          "description": "Rafael is a postdoctoral researcher at Purdue University, with a PhD in applied physics from UNICAMP, where he used deep learning and NLP techniques to detect fake news on Twitter during the COVID-19 pandemic.",
          "speaker": {
            "name": "Rafael Geurgas Zavarizz",
            "photo": "/images/udl2024/rafael_zavarizz.png",
            "description": "Rafael Zavarizz is a postdoctoral researcher at Purdue University, specializing in deep learning and NLP for fake news detection."
          },
          "eventReminder": "https://www.youtube.com/live/rTJi4HHcTV8?si=QkPkI8mMRwWxTHJ2"
        }
      ]
    }
  ]
}
